{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "handy-mortality",
   "metadata": {},
   "source": [
    "This notebook is created to analyse simple correlations between entailment measures and human intution. Simply specify the file you want to analyse and run the remaining code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "based-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_location = \"../data/output/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "specified-spider",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/benjaminrodatz/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from operations.composition import *\n",
    "from operations.similarity_measures import *\n",
    "from operations.logical_negation import *\n",
    "from operations.worldly_context_creation import *\n",
    "from operations.helpers import *\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import csv\n",
    "import random\n",
    "\n",
    "\n",
    "from matplotlib.lines import Line2D \n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "persistent-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = []\n",
    "df = None\n",
    "\n",
    "with open(data_file_location, newline='') as csvfile:\n",
    "        # with open('df_i4_all_idneg.csv', newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        for row in spamreader:\n",
    "            test = row\n",
    "            file.append(row)\n",
    "\n",
    "        df = pd.DataFrame(file[1:])\n",
    "        df.columns = file[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "talented-kidney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_baseline_trace\n",
      "4_baseline_kE1\n",
      "4_baseline_kE2\n",
      "4_baseline_khyp1\n",
      "4_baseline_khyp2\n",
      "4_worldly_context_trace\n",
      "4_worldly_context_kE1\n",
      "4_worldly_context_kE2\n",
      "4_worldly_context_khyp1\n",
      "4_worldly_context_khyp2\n",
      "4_negated_trace\n",
      "4_negated_kE1\n",
      "4_negated_kE2\n",
      "4_negated_khyp1\n",
      "4_negated_khyp2\n",
      "4_negated_scaled_trace\n",
      "4_negated_scaled_kE1\n",
      "4_negated_scaled_kE2\n",
      "4_negated_scaled_khyp1\n",
      "4_negated_scaled_khyp2\n",
      "4_negated_hyp_trace\n",
      "4_negated_hyp_kE1\n",
      "4_negated_hyp_kE2\n",
      "4_negated_hyp_khyp1\n",
      "4_negated_hyp_khyp2\n",
      "4_negated_hyp_scaled_trace\n",
      "4_negated_hyp_scaled_kE1\n",
      "4_negated_hyp_scaled_kE2\n",
      "4_negated_hyp_scaled_khyp1\n",
      "4_negated_hyp_scaled_khyp2\n",
      "4_wc_minux_hyp_trace\n",
      "4_wc_minux_hyp_kE1\n",
      "4_wc_minux_hyp_kE2\n",
      "4_wc_minux_hyp_khyp1\n",
      "4_wc_minux_hyp_khyp2\n",
      "4_wc_minux_hyp_scaled_trace\n",
      "4_wc_minux_hyp_scaled_kE1\n",
      "4_wc_minux_hyp_scaled_kE2\n",
      "4_wc_minux_hyp_scaled_khyp1\n",
      "4_wc_minux_hyp_scaled_khyp2\n",
      "4_context_minus_hyp_trace\n",
      "4_context_minus_hyp_kE1\n",
      "4_context_minus_hyp_kE2\n",
      "4_context_minus_hyp_khyp1\n",
      "4_context_minus_hyp_khyp2\n",
      "4_context_minus_hyp_scaled_trace\n",
      "4_context_minus_hyp_scaled_kE1\n",
      "4_context_minus_hyp_scaled_kE2\n",
      "4_context_minus_hyp_scaled_khyp1\n",
      "4_context_minus_hyp_scaled_khyp2\n"
     ]
    }
   ],
   "source": [
    "# convert the rows after row 5 to numeric.\n",
    "# It is assumed that these only contain numbers which can then be compared to the human rating.\n",
    "# This cell prints all rows which have been found and will eventually be compared to the human rating.\n",
    "\n",
    "df[\"MEANRATING\"] = pd.to_numeric(df[\"MEANRATING\"])\n",
    "for col in df.columns[5:]:\n",
    "    print(col)\n",
    "    df[col] = pd.to_numeric(df[col])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "incident-cover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MEANRATING                          1.000\n",
       "4_baseline_trace                    0.575\n",
       "4_baseline_kE1                      0.551\n",
       "4_baseline_kE2                      0.464\n",
       "4_baseline_khyp1                   -0.003\n",
       "4_baseline_khyp2                    0.303\n",
       "4_worldly_context_trace             0.628\n",
       "4_worldly_context_kE1               0.599\n",
       "4_worldly_context_kE2               0.440\n",
       "4_worldly_context_khyp1             0.475\n",
       "4_worldly_context_khyp2             0.294\n",
       "4_negated_trace                     0.627\n",
       "4_negated_kE1                       0.599\n",
       "4_negated_kE2                       0.437\n",
       "4_negated_khyp1                     0.487\n",
       "4_negated_khyp2                     0.295\n",
       "4_negated_scaled_trace              0.627\n",
       "4_negated_scaled_kE1                0.602\n",
       "4_negated_scaled_kE2                0.436\n",
       "4_negated_scaled_khyp1              0.365\n",
       "4_negated_scaled_khyp2              0.293\n",
       "4_negated_hyp_trace                 0.625\n",
       "4_negated_hyp_kE1                   0.602\n",
       "4_negated_hyp_kE2                   0.433\n",
       "4_negated_hyp_khyp1                 0.479\n",
       "4_negated_hyp_khyp2                 0.296\n",
       "4_negated_hyp_scaled_trace          0.630\n",
       "4_negated_hyp_scaled_kE1            0.606\n",
       "4_negated_hyp_scaled_kE2            0.439\n",
       "4_negated_hyp_scaled_khyp1          0.379\n",
       "4_negated_hyp_scaled_khyp2          0.295\n",
       "4_wc_minux_hyp_trace                0.583\n",
       "4_wc_minux_hyp_kE1                  0.424\n",
       "4_wc_minux_hyp_kE2                  0.240\n",
       "4_wc_minux_hyp_khyp1                0.257\n",
       "4_wc_minux_hyp_khyp2                0.306\n",
       "4_wc_minux_hyp_scaled_trace         0.614\n",
       "4_wc_minux_hyp_scaled_kE1           0.504\n",
       "4_wc_minux_hyp_scaled_kE2           0.304\n",
       "4_wc_minux_hyp_scaled_khyp1         0.448\n",
       "4_wc_minux_hyp_scaled_khyp2         0.310\n",
       "4_context_minus_hyp_trace           0.563\n",
       "4_context_minus_hyp_kE1            -0.049\n",
       "4_context_minus_hyp_kE2             0.004\n",
       "4_context_minus_hyp_khyp1           0.064\n",
       "4_context_minus_hyp_khyp2           0.070\n",
       "4_context_minus_hyp_scaled_trace    0.606\n",
       "4_context_minus_hyp_scaled_kE1     -0.021\n",
       "4_context_minus_hyp_scaled_kE2      0.021\n",
       "4_context_minus_hyp_scaled_khyp1    0.033\n",
       "4_context_minus_hyp_scaled_khyp2    0.032\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell calculates and prints the correlations. \n",
    "# There may be some filtering going on, which can be adapted to once need.\n",
    "cols = []\n",
    "filter_term = \"\"\n",
    "\n",
    "for col in df.columns:        \n",
    "    if filter_term in col:\n",
    "        cols.append(col)\n",
    "\n",
    "correlations = df[cols].corrwith(df[\"MEANRATING\"])\n",
    "\n",
    "\n",
    "# round(correlations[correlations > 0.5])\n",
    "round(correlations, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-truck",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-ability",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
